{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "cookies = {\n",
    "        'JSESSIONID': 'F5CE3110AA6AE1BFF3B9F746E5574157',\n",
    "    }\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'http://tools.nlp.itu.edu.tr/IsTurkish',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 OPR/115.0.0.0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def isTurkish(word):\n",
    "    \n",
    "    # Formu POST ile gönder\n",
    "    form_data = {\n",
    "        'input': word  # Kelimeyi input alanına gönderiyoruz\n",
    "    }\n",
    "\n",
    "    response = requests.post('http://tools.nlp.itu.edu.tr/IsTurkish', cookies=cookies, headers=headers, data=form_data, verify=False)\n",
    "\n",
    "    # Sayfa içeriğini BeautifulSoup ile işle\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Sayfa içeriğinde yer alan 'output' alanını al\n",
    "    result = soup.find('textarea', {'name': 'output'})\n",
    "\n",
    "    if result:\n",
    "        # 'output' alanındaki sonucu sadece true/false olarak döndür\n",
    "        result_text = result.get_text().strip().lower()\n",
    "        if \"true\" in result_text:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_words(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    new_roots = {}\n",
    "    \n",
    "    for word, word_id in data.items():\n",
    "\n",
    "        # Fiil olup olmadığını kontrol et\n",
    "        potential_verb = word + 'mak' if word[-1] not in ['e'] else word + 'mek'\n",
    "\n",
    "        if isTurkish(potential_verb):\n",
    "            # Fiil ise ünlü daralmasını uygula\n",
    "            \n",
    "            if(word in ['de','ye','ne']):\n",
    "                if word == 'de':\n",
    "                    new_roots['di'] = word_id\n",
    "                elif word == 'ye':\n",
    "                    new_roots['yi'] = word_id\n",
    "                elif word == 'ne':\n",
    "                    new_roots['ni'] = word_id\n",
    "\n",
    "            elif(word[-1] in 'ae'):\n",
    "                if word[-1] == 'a' and ('a' in word[:-1] or 'ı' in word[:-1]):\n",
    "                    new_word = word[:-1] + 'ı'  # 'a' -> 'ı'\n",
    "                    new_roots[new_word] = word_id\n",
    "                elif word[-1] == 'a' and ('a' not in word[:-1] or 'u' in word[:-1]):\n",
    "                    new_word = word[:-1] + 'u'  # 'a' -> 'u'\n",
    "                    new_roots[new_word] = word_id\n",
    "                elif word[-1] == 'e' and ('e' in word[:-1] or 'i' in word[:-1]):\n",
    "                    new_word = word[:-1] + 'i'  # 'e' -> 'i'\n",
    "                    new_roots[new_word] = word_id\n",
    "                else:\n",
    "                    new_word = word[:-1] + 'ü'  # 'e' -> 'ü'\n",
    "                    new_roots[new_word] = word_id\n",
    "    \n",
    "    # Orijinal kelimeler ve yeni kökleri birleştir\n",
    "    data.update(new_roots)\n",
    "    \n",
    "    # Güncellenmiş veriyi JSON dosyasına yaz\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    return new_roots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daralmaliListe = process_words('/Users/yusuf/Desktop/tokenizer/turkish_tokenizer/kokler_v05.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
