{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load gemma2 tokenizer from huggingface\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = AutoTokenizer.from_pretrained(\"gemma_tokenizer\")\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma_tokenizer/tokenizer_config.json',\n",
       " 'gemma_tokenizer/special_tokens_map.json',\n",
       " 'gemma_tokenizer/tokenizer.model',\n",
       " 'gemma_tokenizer/added_tokens.json',\n",
       " 'gemma_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_tokenizer.save_pretrained(\"gemma_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108508</th>\n",
       "      <td>ew</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157965</th>\n",
       "      <td>bu</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106397</th>\n",
       "      <td>ark</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172922</th>\n",
       "      <td>})</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14667</th>\n",
       "      <td>▁res</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20537</th>\n",
       "      <td>▁ag</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83476</th>\n",
       "      <td>▁tra</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102932</th>\n",
       "      <td>▁cont</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156301</th>\n",
       "      <td>▁et</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>▁some</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123711</th>\n",
       "      <td>pro</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>но</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125276</th>\n",
       "      <td>ga</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152999</th>\n",
       "      <td>▁if</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238381</th>\n",
       "      <td>ings</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207063</th>\n",
       "      <td>▁imp</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155329</th>\n",
       "      <td>AT</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175558</th>\n",
       "      <td>min</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148490</th>\n",
       "      <td>cri</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218419</th>\n",
       "      <td>▁fo</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107659</th>\n",
       "      <td>del</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48615</th>\n",
       "      <td>up</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250181</th>\n",
       "      <td>old</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122984</th>\n",
       "      <td>ob</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144948</th>\n",
       "      <td>▁their</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155912</th>\n",
       "      <td>gra</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211279</th>\n",
       "      <td>▁ri</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57627</th>\n",
       "      <td>▁Re</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193970</th>\n",
       "      <td>AR</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>ef</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53214</th>\n",
       "      <td>ST</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96131</th>\n",
       "      <td>ен</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17248</th>\n",
       "      <td>now</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104365</th>\n",
       "      <td>lan</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49541</th>\n",
       "      <td>▁fe</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212132</th>\n",
       "      <td>ular</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18354</th>\n",
       "      <td>▁bo</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177269</th>\n",
       "      <td>cre</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175876</th>\n",
       "      <td>ener</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160692</th>\n",
       "      <td>fe</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token    id\n",
       "108508      ew  1000\n",
       "157965      bu  1001\n",
       "106397     ark  1002\n",
       "172922      })  1003\n",
       "14667     ▁res  1004\n",
       "20537      ▁ag  1005\n",
       "83476     ▁tra  1006\n",
       "102932   ▁cont  1007\n",
       "156301     ▁et  1008\n",
       "2390     ▁some  1009\n",
       "123711     pro  1010\n",
       "14453       но  1011\n",
       "125276      ga  1012\n",
       "152999     ▁if  1013\n",
       "238381    ings  1014\n",
       "207063    ▁imp  1015\n",
       "155329      AT  1016\n",
       "175558     min  1017\n",
       "148490     cri  1018\n",
       "218419     ▁fo  1019\n",
       "107659     del  1020\n",
       "48615       up  1021\n",
       "250181     old  1022\n",
       "122984      ob  1023\n",
       "144948  ▁their  1024\n",
       "155912     gra  1025\n",
       "211279     ▁ri  1026\n",
       "57627      ▁Re  1027\n",
       "193970      AR  1028\n",
       "20175       ef  1029\n",
       "53214       ST  1030\n",
       "96131       ен  1031\n",
       "17248      now  1032\n",
       "104365     lan  1033\n",
       "49541      ▁fe  1034\n",
       "212132    ular  1035\n",
       "18354      ▁bo  1036\n",
       "177269     cre  1037\n",
       "175876    ener  1038\n",
       "160692      fe  1039"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# get string, int pairs from gemma_tokenizer.vocab\n",
    "\n",
    "gemma_vocab = gemma_tokenizer.get_vocab()\n",
    "\n",
    "vocab_df = pd.DataFrame(gemma_vocab.items(), columns=['token', 'id'])\n",
    "vocab_df = vocab_df.sort_values('id')\n",
    "vocab_df[1000:1040]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "unk_token = '<unk>'\n",
    "spl_tokens = ['<bos>', '<eos>', '<unk>', '<pad>', '<start_of_turn>', '<end_of_turn>']\n",
    "\n",
    "vocab['<pad>'] = 0\n",
    "vocab['<bos>'] = 1\n",
    "vocab['<eos>'] = 2\n",
    "vocab['<unk>'] = 3\n",
    "vocab['<mask>'] = 4\n",
    "vocab['<2mass>'] = 5\n",
    "vocab['[@BOS@]'] = 6\n",
    "for i in range(50):\n",
    "    vocab[f'<unused{i}>'] = i + 7\n",
    "vocab['<start_of_turn>'] = 57\n",
    "vocab['<end_of_turn>'] = 58\n",
    "\n",
    "vocab\n",
    "\n",
    "#spl_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'A', 'aba', 'Aba', 'abadi', 'Abadi', 'abaküs', 'Abaküs', 'aban', 'Aban']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predefined_words = []\n",
    "with open(\"veri/first_12500_titled.txt\") as f:\n",
    "    for line in f:\n",
    "        # remove newline character\n",
    "        if line.strip() != \"\":\n",
    "          predefined_words.append(line.strip())\n",
    "predefined_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "ekler = [\n",
    "    \"lık\", \"lik\", \"luk\", \"lük\",\n",
    "    \"lı\", \"li\", \"lu\", \"lü\",\n",
    "    \"sız\", \"siz\", \"suz\", \"süz\",\n",
    "    \"cı\", \"ci\", \"cu\", \"cü\",\n",
    "    \"çı\", \"çi\", \"çu\", \"çü\",\n",
    "    \"cık\", \"cik\", \"cuk\", \"cük\",\n",
    "    \"çık\", \"çik\", \"çuk\", \"çük\",\n",
    "    \"ca\", \"ce\",\n",
    "    \"ça\", \"çe\",\n",
    "    \"daş\", \"deş\",\n",
    "    \"taş\", \"teş\",\n",
    "    \"ncı\", \"nci\", \"ncu\", \"ncü\",\n",
    "    \"ar\", \"er\",\n",
    "    \"şar\", \"şer\",\n",
    "    \"sal\", \"sel\",\n",
    "    \"tı\", \"ti\", \"tu\", \"tü\",\n",
    "    \"aç\", \"eç\",\n",
    "    \"ak\", \"ek\",\n",
    "    \"an\", \"en\",\n",
    "    \"cıl\", \"cil\", \"cul\", \"cül\",\n",
    "    \"çıl\", \"çil\", \"çul\",\n",
    "    \"cileyin\",\n",
    "    \"ç\",\n",
    "    \"gil\", \"gül\", \"kıl\", \"kil\",\n",
    "    \"ge\", \"ka\",\n",
    "    \"kan\", \"ken\",\n",
    "    \"kek\",\n",
    "    \"man\", \"men\",\n",
    "    \"la\",\n",
    "    \"lak\", \"lek\",\n",
    "    \"layın\", \"leyin\",\n",
    "    \"msı\", \"msi\", \"msu\",\n",
    "    \"mtırak\",\n",
    "    \"rak\", \"rek\",\n",
    "    \"sak\", \"sek\",\n",
    "    \"sı\", \"si\", \"su\", \"sü\",\n",
    "    \"şın\", \"şin\",\n",
    "    \"t\",\n",
    "    \"z\",\n",
    "    \"la\", \"le\",\n",
    "    \"al\", \"el\",\n",
    "    \"l\",\n",
    "    \"a\", \"e\",\n",
    "    \"ar\", \"er\",\n",
    "    \"da\", \"de\",\n",
    "    \"k\",\n",
    "    \"kır\", \"kir\", \"kur\", \"kür\",\n",
    "    \"msa\", \"mse\",\n",
    "    \"r\",\n",
    "    \"sa\", \"se\",\n",
    "    \"l\",\n",
    "    \"ma\", \"me\",\n",
    "    \"n\",\n",
    "    \"r\",\n",
    "    \"t\",\n",
    "    \"ş\",\n",
    "    \"dır\", \"dir\", \"dur\", \"dür\",\n",
    "    \"tır\", \"tir\", \"tur\", \"tür\",\n",
    "    \"a\", \"e\",\n",
    "    \"ala\", \"ele\",\n",
    "    \"ar\", \"er\",\n",
    "    \"ı\", \"ü\",\n",
    "    \"k\",\n",
    "    \"k\",\n",
    "    \"p\",\n",
    "    \"a\", \"e\",\n",
    "    \"ağan\", \"eğen\",\n",
    "    \"ak\", \"ek\",\n",
    "    \"alak\", \"elek\",\n",
    "    \"amak\", \"emek\",\n",
    "    \"anak\", \"enek\",\n",
    "    \"ca\", \"ce\",\n",
    "    \"ç\",\n",
    "    \"aç\", \"eç\",\n",
    "    \"dı\", \"di\", \"du\", \"dü\",\n",
    "    \"tı\", \"ti\", \"tu\", \"tü\",\n",
    "    \"ga\", \"ge\",\n",
    "    \"gaç\", \"geç\", \"kaç\",\n",
    "    \"gıç\", \"giç\", \"guç\",\n",
    "    \"maca\", \"mece\",\n",
    "    \"maç\", \"meç\",\n",
    "    \"man\", \"men\",\n",
    "    \"mık\", \"mik\", \"muk\",\n",
    "    \"n\",\n",
    "    \"t\",\n",
    "    \"a\", \"e\",\n",
    "    \"ga\", \"ge\",\n",
    "    \"gıç\", \"giç\", \"guç\",\n",
    "    \"n\",\n",
    "    \"t\",\n",
    "    \"lar\", \"ler\", # Çokluk eki\n",
    "    \"mı\", \"mi\", \"mu\", \"mü\", # Soru eki\n",
    "    \"m\", \"n\", \"ı\", \"i\", \"u\", \"ü\", \"sı\", \"si\", \"su\", \"sü\", # İyelik ekleri\n",
    "    \"da\", \"de\", \"ta\", \"te\", # Bulunma hali eki\n",
    "    \"dan\", \"den\", \"tan\", \"ten\", # Ayrılma hali eki\n",
    "    \"ın\", \"in\", \"un\", \"ün\", \"nın\", \"nin\", \"nun\", \"nün\", # İlgi hali eki\n",
    "    \"y\", # Koruyucu ünsüz\n",
    "    \"n\", # Koruyucu ünsüz\n",
    "    \"ki\", # Aitlik eki\n",
    "    \"yor\", \"makta\", \"mede\", # Şimdiki zaman ekleri\n",
    "    \"acak\", \"ecek\", \"acağ\", \"eceğ\", # Gelecek zaman ekleri\n",
    "    \"r\", \"ar\", \"er\", # Geniş zaman ekleri\n",
    "    \"malı\", \"meli\", # Gereklilik kipi eki\n",
    "    \"sa\", \"se\", # Dilek-şart kipi eki\n",
    "    \"a\", \"e\", # İstek kipi eki\n",
    "    \"dı\", \"di\", \"du\", \"dü\", \"tı\", \"ti\", \"tu\", \"tü\", # Görülen geçmiş zaman eki\n",
    "    \"mış\", \"miş\", \"muş\", \"müş\", # Öğrenilen geçmiş zaman eki\n",
    "    \"im\", \"sin\", \"dir\", \"iz\", \"siniz\", \"dirler\", # Ek-fiilin şimdiki/geniş zaman eki\n",
    "    \"dı\", \"di\", \"du\", \"dü\", \"tı\", \"ti\", \"tu\", \"tü\", # Ek-fiilin görülen geçmiş zaman eki\n",
    "    \"mış\", \"miş\", \"muş\", \"müş\", # Ek-fiilin öğrenilen geçmiş zaman eki\n",
    "    \"sa\", \"se\", # Ek-fiilin şart eki\n",
    "    \"yacak\", \"yecek\", # Katmerli birleşik çekim eki\n",
    "    \"miş\", \"miş\", \"muş\", \"müş\", # Katmerli birleşik çekim eki\n",
    "    \"dı\", \"di\", \"du\", \"dü\", \"tı\", \"ti\", \"tu\", \"tü\" # Katmerli birleşik çekim eki\n",
    "]\n",
    "\n",
    "print(len(set(ekler)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25171"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edatlar = [\"gibi\", \"için\", \"kadar\", \"ile\", \"üzere\", \"sanki\", \"den\", \"dolayı\", \"doğru\", \"önce\", \"sonra\", \"karşı\", \"göre\", \"rağmen\", \"beri\", \"üzere\", \"yönelik\", \"ait\"]\n",
    "bağlaçlar = [\"ve\", \"ama\", \"ile\", \"de\", \"çünkü\", \"eğer\", \"fakat\", \"lakin\", \"ki\", \"ya\", \"yahut\", \"ya da\", \"veya\", \"hem\", \"oysa\", \"oysa ki\", \"nitekim\", \"sanki\", \"zira\", \"öyle ki\", \"şu var ki\", \"lâkin\", \"üstelik\", \"ne ... ne\", \"hem ... hem\", \"ister ... ister\", \"gerek ... gerek(se)\", \"ancak\", \"bari\"]\n",
    "ünlemler = [\"ah\", \"ey\", \"oha\", \"öf\", \"hah\", \"ya\", \"aman\", \"hey\", \"hadi\", \"vah\", \"eyvah\", \"uff\", \"of\", \"oh\", \"heyecanla\", \"tamam\", \"çüş\"]\n",
    "cekim_ekleri = [\"ler\", \"lar\", \"i\", \"e\", \"den\", \"de\", \"im\", \"in\", \"i\", \"imiz\", \"iniz\", \"leri\", \"ın\", \"in\", \"un\", \"ün\", \"ca\", \"ce\", \"le\", \"la\", \"r\", \"yor\", \"mekte\", \"di\", \"miş\", \"ecek\", \"meli\", \"malı\", \"se\", \"sa\", \"ayım\", \"ydi\", \"ymiş\", \"yse\", \"dir\", \"m\", \"n\", \"k\", \"iz\", \"siniz\", \"ler\", \"mak\", \"mek\"]\n",
    "yapim_ekleri = [\"lık\", \"li\", \"sız\", \"ci\", \"ce\", \"daş\", \"üncü\", \"msı\", \"cık\", \"tı\", \"cıl\", \"deki\", \"la\", \"al\", \"l\", \"a\", \"ar\", \"da\", \"ık\", \"ımsa\", \"laş\", \"sa\", \"ca\", \"acak\", \"ak\", \"ge\", \"gı\", \"ı\", \"ıcı\", \"ık\", \"ım\", \"nç\", \"ıntı\", \"ır\", \"ış\", \"ma\", \"dır\", \"l\", \"n\", \"t\"]\n",
    "\n",
    "# doldurulacaklar = predefined_words + edatlar + bağlaçlar + ünlemler + cekim_ekleri + yapim_ekleri\n",
    "# TypeError: can only concatenate list (not \"tuple\") to list\n",
    "doldurulacaklar = set()\n",
    "doldurulacaklar.update(predefined_words)\n",
    "doldurulacaklar.update(edatlar)\n",
    "doldurulacaklar.update(bağlaçlar)\n",
    "doldurulacaklar.update(ünlemler)\n",
    "doldurulacaklar.update(cekim_ekleri)\n",
    "doldurulacaklar.update(yapim_ekleri)\n",
    "doldurulacaklar.update(ekler)\n",
    "doldurulacaklar = list(doldurulacaklar)\n",
    "len(doldurulacaklar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"Çözgü\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":1, \"content\":\"Sınır\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":2, \"content\":\"Şelale\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":3, \"content\":\"Aperitif\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":4, \"content\":\"rakım\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":5, \"content\":\"refleks\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":6, \"content\":\"arz\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":7, \"content\":\"Herek\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":8, \"content\":\"Hasar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":9, \"content\":\"Sima\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":10, \"content\":\"platonik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":11, \"content\":\"şalvar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":12, \"content\":\"Dönüm\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":13, \"content\":\"Mektup\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":14, \"content\":\"Taflan\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":15, \"content\":\"Gökkuzgun\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":16, \"content\":\"biçimli\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":17, \"content\":\"Borik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":18, \"content\":\"Takt\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":19, \"content\":\"şurup\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":20, \"content\":\"Mukaddime\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":21, \"content\":\"Robotik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":22, \"content\":\"sabah\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":23, \"content\":\"Gitar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":24, \"content\":\"Bakan\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":25, \"content\":\"bilim\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":26, \"content\":\"Pırasa\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":27, \"content\":\"mızıka\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":28, \"content\":\"Feyiz\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":29, \"content\":\"uff\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":30, \"content\":\"geveze\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":31, \"content\":\"ansiklopedi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":32, \"content\":\"şal\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":33, \"content\":\"kokpit\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":34, \"content\":\"Kelaynak\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":35, \"content\":\"Hilafet\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":36, \"content\":\"sinirli\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":37, \"content\":\"tekabül\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":38, \"content\":\"sanatsever\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":39, \"content\":\"silindir\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":40, \"content\":\"Küfe\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":41, \"content\":\"Teslim\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":42, \"content\":\"Ocak\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":43, \"content\":\"paye\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":44, \"content\":\"Başkent\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":45, \"content\":\"sızıntı\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":46, \"content\":\"dile\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":47, \"content\":\"rafine\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":48, \"content\":\"Tezgah\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":49, \"content\":\"Tamir\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50, \"content\":\"rutubet\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":51, \"content\":\"Yüzleş\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":52, \"content\":\"bitişik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":53, \"content\":\"bumerang\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":54, \"content\":\"tuba\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":55, \"content\":\"Müstesna\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":56, \"content\":\"Söylenti\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":57, \"content\":\"neyzen\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":58, \"content\":\"Bilahare\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":59, \"content\":\"ikbal\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":60, \"content\":\"muhatap\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":61, \"content\":\"Okyanus\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":62, \"content\":\"Kahvehane\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":63, \"content\":\"Soma\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":64, \"content\":\"filizi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":65, \"content\":\"leyin\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":66, \"content\":\"Çer\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":67, \"content\":\"bağır\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":68, \"content\":\"Refika\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":69, \"content\":\"demirhindi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":70, \"content\":\"varidat\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":71, \"content\":\"Piyes\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":72, \"content\":\"tahmini\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":73, \"content\":\"revizyonizm\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":74, \"content\":\"kros\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":75, \"content\":\"ayrıca\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":76, \"content\":\"Fetiş\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":77, \"content\":\"Maraton\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":78, \"content\":\"Kalker\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":79, \"content\":\"Fanfar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":80, \"content\":\"Konsolos\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":81, \"content\":\"Ziraat\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":82, \"content\":\"bakkal\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":83, \"content\":\"tap\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":84, \"content\":\"Hançer\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":85, \"content\":\"Çıyan\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":86, \"content\":\"Tersle\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":87, \"content\":\"Ahlat\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":88, \"content\":\"betimle\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":89, \"content\":\"kakma\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":90, \"content\":\"maarif\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":91, \"content\":\"Bordür\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":92, \"content\":\"Sıvın\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":93, \"content\":\"Mağlubiyet\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":94, \"content\":\"otopsi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":95, \"content\":\"imge\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":96, \"content\":\"Dolap\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":97, \"content\":\"kolit\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":98, \"content\":\"Poz\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, ...], normalizer=None, pre_tokenizer=Whitespace(), post_processor=None, decoder=None, model=BPE(dropout=None, unk_token=\"<unk>\", continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={}, merges=[]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=unk_token))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.add_tokens(list(doldurulacaklar))\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BpeTrainer(BpeTrainer(min_frequency=16, vocab_size=7001, show_progress=True, special_tokens=[AddedToken(content=\"<bos>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<eos>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<unk>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<pad>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<start_of_turn>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<end_of_turn>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True)], limit_alphabet=1200, initial_alphabet=[], continuing_subword_prefix=None, end_of_word_suffix=None, max_token_length=None, words={}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = BpeTrainer(special_tokens=spl_tokens, vocab_size=7001, limit_alphabet=1200, min_frequency=16)\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Cengiz%20Han</td>\n",
       "      <td>Cengiz Han</td>\n",
       "      <td>Cengiz Han (doğum adıyla Temuçin,  – 18 Ağusto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Film%20%28anlam%...</td>\n",
       "      <td>Film (anlam ayrımı)</td>\n",
       "      <td>Film şu anlamlara gelebilir:\\n\\n Camlara yapış...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Mustafa%20Suphi</td>\n",
       "      <td>Mustafa Suphi</td>\n",
       "      <td>Mehmed Mustafa Subhi (), kısaca Mustafa Suphi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Linux</td>\n",
       "      <td>Linux</td>\n",
       "      <td>Linux (telaffuz: Lin-uks); Linux çekirdeğine d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Bol%C5%9Fevizm</td>\n",
       "      <td>Bolşevizm</td>\n",
       "      <td>Bolşevik, çoğunluktan yana anlamına gelen Rusç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534983</th>\n",
       "      <td>3611624</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Musculus%20ptery...</td>\n",
       "      <td>Musculus pterygoideus lateralis</td>\n",
       "      <td>ağzı kapatan tek kastır. alt çene ramus'a ve ü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534984</th>\n",
       "      <td>3611625</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/%C3%87in%20kad%C...</td>\n",
       "      <td>Çin kadın millî futbol takımı</td>\n",
       "      <td>Çin kadın millî futbol takımı, Çin'i uluslarar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534985</th>\n",
       "      <td>3611628</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Abdurrezak%20KUR...</td>\n",
       "      <td>Abdurrezak KURTULUŞ</td>\n",
       "      <td>1933 yılında Mardin’de doğdu. 1950 yılında Diy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534986</th>\n",
       "      <td>3611631</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/%C4%B0brahim%20T...</td>\n",
       "      <td>İbrahim Turgut</td>\n",
       "      <td>İbrahim Turgut Sayın Cumhurbaşkanı Recep Tayyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534987</th>\n",
       "      <td>3611637</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Burcu%20Pirin%C3...</td>\n",
       "      <td>Burcu Pirinçci</td>\n",
       "      <td>Burcu Dindar (evlilik öncesi Pirinçci) (d. 8 Ş...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534988 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                                url  \\\n",
       "0            10         https://tr.wikipedia.org/wiki/Cengiz%20Han   \n",
       "1            16  https://tr.wikipedia.org/wiki/Film%20%28anlam%...   \n",
       "2            22      https://tr.wikipedia.org/wiki/Mustafa%20Suphi   \n",
       "3            24                https://tr.wikipedia.org/wiki/Linux   \n",
       "4            30       https://tr.wikipedia.org/wiki/Bol%C5%9Fevizm   \n",
       "...         ...                                                ...   \n",
       "534983  3611624  https://tr.wikipedia.org/wiki/Musculus%20ptery...   \n",
       "534984  3611625  https://tr.wikipedia.org/wiki/%C3%87in%20kad%C...   \n",
       "534985  3611628  https://tr.wikipedia.org/wiki/Abdurrezak%20KUR...   \n",
       "534986  3611631  https://tr.wikipedia.org/wiki/%C4%B0brahim%20T...   \n",
       "534987  3611637  https://tr.wikipedia.org/wiki/Burcu%20Pirin%C3...   \n",
       "\n",
       "                                  title  \\\n",
       "0                            Cengiz Han   \n",
       "1                   Film (anlam ayrımı)   \n",
       "2                         Mustafa Suphi   \n",
       "3                                 Linux   \n",
       "4                             Bolşevizm   \n",
       "...                                 ...   \n",
       "534983  Musculus pterygoideus lateralis   \n",
       "534984    Çin kadın millî futbol takımı   \n",
       "534985              Abdurrezak KURTULUŞ   \n",
       "534986                   İbrahim Turgut   \n",
       "534987                   Burcu Pirinçci   \n",
       "\n",
       "                                                     text  \n",
       "0       Cengiz Han (doğum adıyla Temuçin,  – 18 Ağusto...  \n",
       "1       Film şu anlamlara gelebilir:\\n\\n Camlara yapış...  \n",
       "2       Mehmed Mustafa Subhi (), kısaca Mustafa Suphi,...  \n",
       "3       Linux (telaffuz: Lin-uks); Linux çekirdeğine d...  \n",
       "4       Bolşevik, çoğunluktan yana anlamına gelen Rusç...  \n",
       "...                                                   ...  \n",
       "534983  ağzı kapatan tek kastır. alt çene ramus'a ve ü...  \n",
       "534984  Çin kadın millî futbol takımı, Çin'i uluslarar...  \n",
       "534985  1933 yılında Mardin’de doğdu. 1950 yılında Diy...  \n",
       "534986  İbrahim Turgut Sayın Cumhurbaşkanı Recep Tayyi...  \n",
       "534987  Burcu Dindar (evlilik öncesi Pirinçci) (d. 8 Ş...  \n",
       "\n",
       "[534988 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"wikimedia/wikipedia\", \"20231101.tr\")\n",
    "df = ds['train'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534988"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_with_title = df['title'] + \" \" + df['text']\n",
    "texts = texts_with_title.to_list()\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30164"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(texts, trainer=trainer)\n",
    "tokenizer.save(\"custom_bpe_tokenizer.json\")\n",
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"custom_bpe_tokenizer.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akademi akademisyen akademisyen ler ve aile leri ile birlikte aktif çalış ı yor lar\n",
      "['akademi', 'akademisyen', 'akademisyen', 'ler', 've', 'aile', 'leri', 'ile', 'birlikte', 'aktif', 'çalış', 'ı', 'yor', 'lar']\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode(\"akademi akademisyen akademisyenler ve aileleri ile birlikte aktif çalışıyorlar\")\n",
    "print(tokenizer.decode(encoded.ids))\n",
    "print(fast_tokenizer.tokenize(\"akademi akademisyen akademisyenler ve aileleri ile birlikte aktif çalışıyorlar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "akademisyen Ada er ve aile Ada er ad il e birlikte aktif çalış Ahize yor la Adalet\n",
    "['akademisyen', 'l', 'er', 've', 'aile', 'l', 'er', 'i', 'il', 'e', 'birlikte', 'aktif', 'çalış', 'ı', 'yor', 'la', 'r']\n",
    "\n",
    "akade mi akademisyen akademisyenler ve aileleri ile birlikte aktif çalışıyor lar\n",
    "['akade', 'mi', 'akademisyen', 'akademisyenler', 've', 'aileleri', 'ile', 'birlikte', 'aktif', 'çalışıyor', 'lar']\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/alibayram/tr_tokenizer/commit/9c11d1b0ebe5e4b44604caff7ea7a9b1d831a42b', commit_message='Upload tokenizer', commit_description='', oid='9c11d1b0ebe5e4b44604caff7ea7a9b1d831a42b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.push_to_hub(\"alibayram/tr_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer.tokenize(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "a_tokenizer = AutoTokenizer.from_pretrained(\"alibayram/tr_tokenizer\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akademisyen',\n",
       " 'ler',\n",
       " 've',\n",
       " 'aile',\n",
       " 'leri',\n",
       " 'ile',\n",
       " 'birlikte',\n",
       " 'aktif',\n",
       " 'çalış',\n",
       " 'ı',\n",
       " 'yor',\n",
       " 'lar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tokenizer.tokenize(\"Akademisyenler ve aileleri ile birlikte aktif çalışıyorlar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
